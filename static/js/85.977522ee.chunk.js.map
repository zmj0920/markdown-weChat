{"version":3,"sources":["../../markdown-nice/node_modules/codemirror/mode/python/python.js"],"names":["CodeMirror","wordRegexp","words","RegExp","join","str","wordOperators","commonKeywords","commonBuiltins","top","state","scopes","length","registerHelper","concat","defineMode","conf","parserConf","ERRORCLASS","delimiters","singleDelimiters","operators","singleOperators","doubleOperators","doubleDelimiters","tripleDelimiters","i","splice","hangingIndent","indentUnit","myKeywords","myBuiltins","undefined","extra_keywords","extra_builtins","py3","version","Number","identifiers","stringPrefixes","keywords","builtins","tokenBase","stream","sol","lastToken","indent","indentation","type","scopeOffset","offset","eatSpace","lineOffset","pushPyScope","dedent","peek","errorToken","style","tokenBaseInner","inFormat","match","floatLiteral","eat","intLiteral","isFmtString","current","toLowerCase","indexOf","tokenize","delimiter","tokenOuter","charAt","substr","singleline","OUTCLASS","tokenNestedExpr","depth","inner","tokenString","eol","eatWhile","next","singleLineStringErrors","isString","formatStringFactory","tokenStringFactory","pop","push","align","indented","tokenLexer","beginningOfLine","test","lambda","delimiter_index","column","pushBracketScope","slice","external","startState","basecolumn","token","addErr","textAfter","Pass","scope","closing","electricInput","closeBrackets","triples","lineComment","fold","defineMIME","name","split","mod","__webpack_require__"],"mappings":"+EAOC,SAAAA,GACD,aAEA,SAAAC,EAAAC,GACA,WAAAC,OAAA,MAAAD,EAAAE,KAAA,gBAGA,IA4VAC,EA5VAC,EAAAL,EAAA,yBACAM,EAAA,+LACAC,EAAA,+jBAGA,SAAAC,EAAAC,GACA,OAAAA,EAAAC,OAAAD,EAAAC,OAAAC,OAAA,GAHAZ,EAAAa,eAAA,qBAAAN,EAAAO,OAAAN,IAMAR,EAAAe,WAAA,kBAAAC,EAAAC,GAMA,IALA,IAAAC,EAAA,QACAC,EAAAF,EAAAE,YAAAF,EAAAG,kBAAA,4BAEAC,EAAA,CAAAJ,EAAAK,gBAAAL,EAAAM,gBAAAN,EAAAO,iBAAAP,EAAAQ,iBAAAR,EAAAI,WAAA,0DAEAK,EAAA,EAAmBA,EAAAL,EAAAT,OAAsBc,IACzCL,EAAAK,IAAAL,EAAAM,OAAAD,IAAA,GAGA,IAAAE,EAAAX,EAAAW,eAAAZ,EAAAa,WACAC,EAAAvB,EACAwB,EAAAvB,OACAwB,GAAAf,EAAAgB,iBAAAH,IAAAhB,OAAAG,EAAAgB,sBACAD,GAAAf,EAAAiB,iBAAAH,IAAAjB,OAAAG,EAAAiB,iBACA,IAAAC,IAAAlB,EAAAmB,SAAAC,OAAApB,EAAAmB,SAAA,GAEA,GAAAD,EAAA,CAEA,IAAAG,EAAArB,EAAAqB,aAAA,oDACAR,IAAAhB,OAAA,oDACAiB,IAAAjB,OAAA,kCACA,IAAAyB,EAAA,IAAApC,OAAA,2CAAuE,SAClE,CACL,IAAAmC,EAAArB,EAAAqB,aAAA,0BACAR,IAAAhB,OAAA,kBACAiB,IAAAjB,OAAA,kKACA,IAAAyB,EAAA,IAAApC,OAAA,2CAAuE,KAGvE,IAAAqC,EAAAvC,EAAA6B,GACAW,EAAAxC,EAAA8B,GAEA,SAAAW,EAAAC,EAAAjC,GACA,IAAAkC,EAAAD,EAAAC,OAAA,MAAAlC,EAAAmC,UAGA,GAFAD,IAAAlC,EAAAoC,OAAAH,EAAAI,eAEAH,GAAA,MAAAnC,EAAAC,GAAAsC,KAAA,CACA,IAAAC,EAAAxC,EAAAC,GAAAwC,OAEA,GAAAP,EAAAQ,WAAA,CACA,IAAAC,EAAAT,EAAAI,cAEA,OADAK,EAAAH,EAAAI,EAAA3C,GAA2D0C,EAAAH,GAAAK,EAAAX,EAAAjC,IAAA,KAAAiC,EAAAY,SAAA7C,EAAA8C,YAAA,GAC3D,KAEA,IAAAC,EAAAC,EAAAf,EAAAjC,GAEA,OADAuC,EAAA,GAAAK,EAAAX,EAAAjC,KAAA+C,GAAA,IAAAvC,GACAuC,EAIA,OAAAC,EAAAf,EAAAjC,GAGA,SAAAgD,EAAAf,EAAAjC,EAAAiD,GACA,GAAAhB,EAAAQ,WAAA,YAEA,IAAAQ,GAAAhB,EAAAiB,MAAA,wBAEA,GAAAjB,EAAAiB,MAAA,gBACA,IAAAC,GAAA,EAcA,GAZAlB,EAAAiB,MAAA,iCACAC,GAAA,GAGAlB,EAAAiB,MAAA,kBACAC,GAAA,GAGAlB,EAAAiB,MAAA,YACAC,GAAA,GAGAA,EAGA,OADAlB,EAAAmB,IAAA,MACA,SAIA,IAAAC,GAAA,EAkBA,GAhBApB,EAAAiB,MAAA,oBAAAG,GAAA,GAEApB,EAAAiB,MAAA,gBAAAG,GAAA,GAEApB,EAAAiB,MAAA,iBAAAG,GAAA,GAEApB,EAAAiB,MAAA,mCAEAjB,EAAAmB,IAAA,MAEAC,GAAA,GAIApB,EAAAiB,MAAA,kBAAAG,GAAA,GAEAA,EAGA,OADApB,EAAAmB,IAAA,MACA,SAKA,GAAAnB,EAAAiB,MAAArB,GAAA,CACA,IAAAyB,GAAA,IAAArB,EAAAsB,UAAAC,cAAAC,QAAA,KAEA,OAAAH,GAIAtD,EAAA0D,SAyBA,SAAAC,EAAAC,GACA,YAAAH,QAAAE,EAAAE,OAAA,GAAAL,gBAAA,GACAG,IAAAG,OAAA,GAGA,IAAAC,EAAA,GAAAJ,EAAAzD,OACA8D,EAAA,SAEA,SAAAC,EAAAC,GACA,gBAAAjC,EAAAjC,GACA,IAAAmE,EAAAnB,EAAAf,EAAAjC,GAAA,GAUA,MARA,eAAAmE,IACA,KAAAlC,EAAAsB,UACAvD,EAAA0D,SAAAO,EAAAC,EAAA,GACa,KAAAjC,EAAAsB,YACbvD,EAAA0D,SAAAQ,EAAA,EAAAD,EAAAC,EAAA,GAAyEE,IAIzED,GAIA,SAAAC,EAAAnC,EAAAjC,GACA,MAAAiC,EAAAoC,OAGA,GAFApC,EAAAqC,SAAA,eAEArC,EAAAmB,IAAA,OAEA,GADAnB,EAAAsC,OACAR,GAAA9B,EAAAoC,MAAA,OAAAL,MACW,IAAA/B,EAAAiB,MAAAS,GAEX,OADA3D,EAAA0D,SAAAE,EACAI,EACW,GAAA/B,EAAAiB,MAAA,MAEX,OAAAc,EACW,GAAA/B,EAAAiB,MAAA,KAAyB,GAGpC,OADAlD,EAAA0D,SAAAO,EAAA,GACAhC,EAAAsB,UAAAS,EAAkDhE,EAAA0D,SAAAzB,EAAAjC,GACvC,GAAAiC,EAAAiB,MAAA,MACX,OAAAc,EACW,GAAA/B,EAAAiB,MAAA,KAEX,OAAA1C,EAEAyB,EAAAmB,IAAA,QAIA,GAAAW,EAAA,CACA,GAAAxD,EAAAiE,uBAAA,OAAAhE,EAAmER,EAAA0D,SAAAE,EAGnE,OAAAI,EAIA,OADAI,EAAAK,UAAA,EACAL,EApFAM,CAAAzC,EAAAsB,UAAAvD,EAAA0D,UACA1D,EAAA0D,SAAAzB,EAAAjC,KAJAA,EAAA0D,SA0FA,SAAAC,EAAAC,GACA,YAAAH,QAAAE,EAAAE,OAAA,GAAAL,gBAAA,GACAG,IAAAG,OAAA,GAGA,IAAAC,EAAA,GAAAJ,EAAAzD,OACA8D,EAAA,SAEA,SAAAI,EAAAnC,EAAAjC,GACA,MAAAiC,EAAAoC,OAGA,GAFApC,EAAAqC,SAAA,WAEArC,EAAAmB,IAAA,OAEA,GADAnB,EAAAsC,OACAR,GAAA9B,EAAAoC,MAAA,OAAAL,MACW,IAAA/B,EAAAiB,MAAAS,GAEX,OADA3D,EAAA0D,SAAAE,EACAI,EAEA/B,EAAAmB,IAAA,QAIA,GAAAW,EAAA,CACA,GAAAxD,EAAAiE,uBAAA,OAAAhE,EAAmER,EAAA0D,SAAAE,EAGnE,OAAAI,EAIA,OADAI,EAAAK,UAAA,EACAL,EAzHAO,CAAA1C,EAAAsB,UAAAvD,EAAA0D,UACA1D,EAAA0D,SAAAzB,EAAAjC,IAOA,QAAAgB,EAAA,EAAqBA,EAAAL,EAAAT,OAAsBc,IAC3C,GAAAiB,EAAAiB,MAAAvC,EAAAK,IAAA,iBAGA,OAAAiB,EAAAiB,MAAAzC,GAAA,cACA,KAAAT,EAAAmC,WAAAF,EAAAiB,MAAAtB,GAAA,WACAK,EAAAiB,MAAApB,IAAAG,EAAAiB,MAAAtD,GAAA,UACAqC,EAAAiB,MAAAnB,GAAA,UACAE,EAAAiB,MAAA,8BAEAjB,EAAAiB,MAAAtB,GACA,OAAA5B,EAAAmC,WAAA,SAAAnC,EAAAmC,UAAA,MACA,YAIAF,EAAAsC,OACAtB,EAAA,KAAAzC,GAmGA,SAAAmC,EAAA3C,GACA,WAAAD,EAAAC,GAAAsC,MACAtC,EAAAC,OAAA2E,MAGA5E,EAAAC,OAAA4E,KAAA,CACArC,OAAAzC,EAAAC,GAAAwC,OAAAlC,EAAAa,WACAmB,KAAA,KACAwC,MAAA,OAaA,SAAAlC,EAAAX,EAAAjC,GAGA,IAFA,IAAA+E,EAAA9C,EAAAI,cAEArC,EAAAC,OAAAC,OAAA,GAAAH,EAAAC,GAAAwC,OAAAuC,GAAA,CACA,SAAAhF,EAAAC,GAAAsC,KAAA,SACAtC,EAAAC,OAAA2E,MAGA,OAAA7E,EAAAC,GAAAwC,QAAAuC,EAGA,SAAAC,EAAA/C,EAAAjC,GACAiC,EAAAC,QAAAlC,EAAAiF,iBAAA,GACA,IAAAlC,EAAA/C,EAAA0D,SAAAzB,EAAAjC,GACAuD,EAAAtB,EAAAsB,UAEA,GAAAvD,EAAAiF,iBAAA,KAAA1B,EAAA,OAAAtB,EAAAiB,MAAAtB,GAAA,UAAAH,EAAA,WAAAjB,EAQA,GAPA,KAAA0E,KAAA3B,KAAAvD,EAAAiF,iBAAA,GACA,YAAAlC,GAAA,WAAAA,GAAA,QAAA/C,EAAAmC,YAAAY,EAAA,QAEA,QAAAQ,GAAA,UAAAA,IAAAvD,EAAA4C,QAAA,GACA,UAAAW,IAAAvD,EAAAmF,QAAA,GACA,KAAA5B,GAAAvD,EAAAmF,QAAA,MAAApF,EAAAC,GAAAsC,MAAAK,EAAA3C,GAEA,GAAAuD,EAAArD,SAAA,iBAAAgF,KAAAnC,GAAA,CACA,IAAAqC,EAAA,MAAkC3B,QAAAF,GAIlC,IAHA,GAAA6B,GAnCA,SAAAnD,EAAAjC,EAAAsC,GACA,IAAAwC,EAAA7C,EAAAiB,MAAA,uBAAyC,QAAAjB,EAAAoD,SAAA,EACzCrF,EAAAC,OAAA4E,KAAA,CACArC,OAAAxC,EAAAoC,OAAAlB,EACAoB,OACAwC,UA8BAQ,CAAArD,EAAAjC,EAAA,MAAuEuF,MAAAH,IAAA,KAGvE,IAFAA,EAAA,MAA8B3B,QAAAF,IAE9B,CACA,GAAAxD,EAAAC,GAAAsC,MAAAiB,EAAmG,OAAA/C,EAAnGR,EAAAoC,OAAApC,EAAAC,OAAA2E,MAAApC,OAAAtB,GASA,OALAlB,EAAA4C,OAAA,GAAAX,EAAAoC,OAAA,MAAAtE,EAAAC,GAAAsC,OACAtC,EAAAC,OAAAC,OAAA,GAAAF,EAAAC,OAAA2E,MACA5E,EAAA4C,QAAA,GAGAG,EAGA,IAAAyC,EAAA,CACAC,WAAA,SAAAC,GACA,OACAhC,SAAA1B,EACA/B,OAAA,EACAuC,OAAAkD,GAAA,EACApD,KAAA,KACAwC,MAAA,OAEA1C,OAAAsD,GAAA,EACAvD,UAAA,KACAgD,QAAA,EACAvC,OAAA,IAGA+C,MAAA,SAAA1D,EAAAjC,GACA,IAAA4F,EAAA5F,EAAA8C,WACA8C,IAAA5F,EAAA8C,YAAA,GACA,IAAAC,EAAAiC,EAAA/C,EAAAjC,GAIA,OAHA+C,GAAA,WAAAA,IAAA/C,EAAAmC,UAAA,WAAAY,GAAA,eAAAA,EAAAd,EAAAsB,UAAAR,GACA,eAAAA,MAAA,MACAd,EAAAoC,OAAArE,EAAAmF,SAAAnF,EAAAmF,QAAA,GACAS,EAAA7C,EAAA,IAAAvC,EAAAuC,GAEAX,OAAA,SAAApC,EAAA6F,GACA,GAAA7F,EAAA0D,UAAA1B,EAAA,OAAAhC,EAAA0D,SAAAe,SAAAnF,EAAAwG,KAAA,EACA,IAAAC,EAAAhG,EAAAC,GACAgG,EAAAD,EAAAzD,MAAAuD,EAAAhC,OAAA,GACA,aAAAkC,EAAAjB,MAAAiB,EAAAjB,OAAAkB,EAAA,KAAwED,EAAAvD,QAAAwD,EAAA9E,EAAA,IAExE+E,cAAA,gBACAC,cAAA,CACAC,QAAA,OAEAC,YAAA,IACAC,KAAA,UAEA,OAAAb,IAEAlG,EAAAgH,WAAA,0BAMAhH,EAAAgH,WAAA,iBACAC,KAAA,SACAhF,gBANA5B,EAMA,6HALAA,EAAA6G,MAAA,QAvWAC,CAAQC,EAAQ","file":"static/js/85.977522ee.chunk.js","sourcesContent":["// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/LICENSE\n(function (mod) {\n  if (typeof exports == \"object\" && typeof module == \"object\") // CommonJS\n    mod(require(\"../../lib/codemirror\"));else if (typeof define == \"function\" && define.amd) // AMD\n    define([\"../../lib/codemirror\"], mod);else // Plain browser env\n    mod(CodeMirror);\n})(function (CodeMirror) {\n  \"use strict\";\n\n  function wordRegexp(words) {\n    return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n  }\n\n  var wordOperators = wordRegexp([\"and\", \"or\", \"not\", \"is\"]);\n  var commonKeywords = [\"as\", \"assert\", \"break\", \"class\", \"continue\", \"def\", \"del\", \"elif\", \"else\", \"except\", \"finally\", \"for\", \"from\", \"global\", \"if\", \"import\", \"lambda\", \"pass\", \"raise\", \"return\", \"try\", \"while\", \"with\", \"yield\", \"in\"];\n  var commonBuiltins = [\"abs\", \"all\", \"any\", \"bin\", \"bool\", \"bytearray\", \"callable\", \"chr\", \"classmethod\", \"compile\", \"complex\", \"delattr\", \"dict\", \"dir\", \"divmod\", \"enumerate\", \"eval\", \"filter\", \"float\", \"format\", \"frozenset\", \"getattr\", \"globals\", \"hasattr\", \"hash\", \"help\", \"hex\", \"id\", \"input\", \"int\", \"isinstance\", \"issubclass\", \"iter\", \"len\", \"list\", \"locals\", \"map\", \"max\", \"memoryview\", \"min\", \"next\", \"object\", \"oct\", \"open\", \"ord\", \"pow\", \"property\", \"range\", \"repr\", \"reversed\", \"round\", \"set\", \"setattr\", \"slice\", \"sorted\", \"staticmethod\", \"str\", \"sum\", \"super\", \"tuple\", \"type\", \"vars\", \"zip\", \"__import__\", \"NotImplemented\", \"Ellipsis\", \"__debug__\"];\n  CodeMirror.registerHelper(\"hintWords\", \"python\", commonKeywords.concat(commonBuiltins));\n\n  function top(state) {\n    return state.scopes[state.scopes.length - 1];\n  }\n\n  CodeMirror.defineMode(\"python\", function (conf, parserConf) {\n    var ERRORCLASS = \"error\";\n    var delimiters = parserConf.delimiters || parserConf.singleDelimiters || /^[\\(\\)\\[\\]\\{\\}@,:`=;\\.\\\\]/; //               (Backwards-compatibility with old, cumbersome config system)\n\n    var operators = [parserConf.singleOperators, parserConf.doubleOperators, parserConf.doubleDelimiters, parserConf.tripleDelimiters, parserConf.operators || /^([-+*/%\\/&|^]=?|[<>=]+|\\/\\/=?|\\*\\*=?|!=|[~!@]|\\.\\.\\.)/];\n\n    for (var i = 0; i < operators.length; i++) {\n      if (!operators[i]) operators.splice(i--, 1);\n    }\n\n    var hangingIndent = parserConf.hangingIndent || conf.indentUnit;\n    var myKeywords = commonKeywords,\n        myBuiltins = commonBuiltins;\n    if (parserConf.extra_keywords != undefined) myKeywords = myKeywords.concat(parserConf.extra_keywords);\n    if (parserConf.extra_builtins != undefined) myBuiltins = myBuiltins.concat(parserConf.extra_builtins);\n    var py3 = !(parserConf.version && Number(parserConf.version) < 3);\n\n    if (py3) {\n      // since http://legacy.python.org/dev/peps/pep-0465/ @ is also an operator\n      var identifiers = parserConf.identifiers || /^[_A-Za-z\\u00A1-\\uFFFF][_A-Za-z0-9\\u00A1-\\uFFFF]*/;\n      myKeywords = myKeywords.concat([\"nonlocal\", \"False\", \"True\", \"None\", \"async\", \"await\"]);\n      myBuiltins = myBuiltins.concat([\"ascii\", \"bytes\", \"exec\", \"print\"]);\n      var stringPrefixes = new RegExp(\"^(([rbuf]|(br)|(fr))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n    } else {\n      var identifiers = parserConf.identifiers || /^[_A-Za-z][_A-Za-z0-9]*/;\n      myKeywords = myKeywords.concat([\"exec\", \"print\"]);\n      myBuiltins = myBuiltins.concat([\"apply\", \"basestring\", \"buffer\", \"cmp\", \"coerce\", \"execfile\", \"file\", \"intern\", \"long\", \"raw_input\", \"reduce\", \"reload\", \"unichr\", \"unicode\", \"xrange\", \"False\", \"True\", \"None\"]);\n      var stringPrefixes = new RegExp(\"^(([rubf]|(ur)|(br))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n    }\n\n    var keywords = wordRegexp(myKeywords);\n    var builtins = wordRegexp(myBuiltins); // tokenizers\n\n    function tokenBase(stream, state) {\n      var sol = stream.sol() && state.lastToken != \"\\\\\";\n      if (sol) state.indent = stream.indentation(); // Handle scope changes\n\n      if (sol && top(state).type == \"py\") {\n        var scopeOffset = top(state).offset;\n\n        if (stream.eatSpace()) {\n          var lineOffset = stream.indentation();\n          if (lineOffset > scopeOffset) pushPyScope(state);else if (lineOffset < scopeOffset && dedent(stream, state) && stream.peek() != \"#\") state.errorToken = true;\n          return null;\n        } else {\n          var style = tokenBaseInner(stream, state);\n          if (scopeOffset > 0 && dedent(stream, state)) style += \" \" + ERRORCLASS;\n          return style;\n        }\n      }\n\n      return tokenBaseInner(stream, state);\n    }\n\n    function tokenBaseInner(stream, state, inFormat) {\n      if (stream.eatSpace()) return null; // Handle Comments\n\n      if (!inFormat && stream.match(/^#.*/)) return \"comment\"; // Handle Number Literals\n\n      if (stream.match(/^[0-9\\.]/, false)) {\n        var floatLiteral = false; // Floats\n\n        if (stream.match(/^[\\d_]*\\.\\d+(e[\\+\\-]?\\d+)?/i)) {\n          floatLiteral = true;\n        }\n\n        if (stream.match(/^[\\d_]+\\.\\d*/)) {\n          floatLiteral = true;\n        }\n\n        if (stream.match(/^\\.\\d+/)) {\n          floatLiteral = true;\n        }\n\n        if (floatLiteral) {\n          // Float literals may be \"imaginary\"\n          stream.eat(/J/i);\n          return \"number\";\n        } // Integers\n\n\n        var intLiteral = false; // Hex\n\n        if (stream.match(/^0x[0-9a-f_]+/i)) intLiteral = true; // Binary\n\n        if (stream.match(/^0b[01_]+/i)) intLiteral = true; // Octal\n\n        if (stream.match(/^0o[0-7_]+/i)) intLiteral = true; // Decimal\n\n        if (stream.match(/^[1-9][\\d_]*(e[\\+\\-]?[\\d_]+)?/)) {\n          // Decimal literals may be \"imaginary\"\n          stream.eat(/J/i); // TODO - Can you have imaginary longs?\n\n          intLiteral = true;\n        } // Zero by itself with no other piece of number.\n\n\n        if (stream.match(/^0(?![\\dx])/i)) intLiteral = true;\n\n        if (intLiteral) {\n          // Integer literals may be \"long\"\n          stream.eat(/L/i);\n          return \"number\";\n        }\n      } // Handle Strings\n\n\n      if (stream.match(stringPrefixes)) {\n        var isFmtString = stream.current().toLowerCase().indexOf('f') !== -1;\n\n        if (!isFmtString) {\n          state.tokenize = tokenStringFactory(stream.current(), state.tokenize);\n          return state.tokenize(stream, state);\n        } else {\n          state.tokenize = formatStringFactory(stream.current(), state.tokenize);\n          return state.tokenize(stream, state);\n        }\n      }\n\n      for (var i = 0; i < operators.length; i++) {\n        if (stream.match(operators[i])) return \"operator\";\n      }\n\n      if (stream.match(delimiters)) return \"punctuation\";\n      if (state.lastToken == \".\" && stream.match(identifiers)) return \"property\";\n      if (stream.match(keywords) || stream.match(wordOperators)) return \"keyword\";\n      if (stream.match(builtins)) return \"builtin\";\n      if (stream.match(/^(self|cls)\\b/)) return \"variable-2\";\n\n      if (stream.match(identifiers)) {\n        if (state.lastToken == \"def\" || state.lastToken == \"class\") return \"def\";\n        return \"variable\";\n      } // Handle non-detected items\n\n\n      stream.next();\n      return inFormat ? null : ERRORCLASS;\n    }\n\n    function formatStringFactory(delimiter, tokenOuter) {\n      while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0) {\n        delimiter = delimiter.substr(1);\n      }\n\n      var singleline = delimiter.length == 1;\n      var OUTCLASS = \"string\";\n\n      function tokenNestedExpr(depth) {\n        return function (stream, state) {\n          var inner = tokenBaseInner(stream, state, true);\n\n          if (inner == \"punctuation\") {\n            if (stream.current() == \"{\") {\n              state.tokenize = tokenNestedExpr(depth + 1);\n            } else if (stream.current() == \"}\") {\n              if (depth > 1) state.tokenize = tokenNestedExpr(depth - 1);else state.tokenize = tokenString;\n            }\n          }\n\n          return inner;\n        };\n      }\n\n      function tokenString(stream, state) {\n        while (!stream.eol()) {\n          stream.eatWhile(/[^'\"\\{\\}\\\\]/);\n\n          if (stream.eat(\"\\\\\")) {\n            stream.next();\n            if (singleline && stream.eol()) return OUTCLASS;\n          } else if (stream.match(delimiter)) {\n            state.tokenize = tokenOuter;\n            return OUTCLASS;\n          } else if (stream.match('{{')) {\n            // ignore {{ in f-str\n            return OUTCLASS;\n          } else if (stream.match('{', false)) {\n            // switch to nested mode\n            state.tokenize = tokenNestedExpr(0);\n            if (stream.current()) return OUTCLASS;else return state.tokenize(stream, state);\n          } else if (stream.match('}}')) {\n            return OUTCLASS;\n          } else if (stream.match('}')) {\n            // single } in f-string is an error\n            return ERRORCLASS;\n          } else {\n            stream.eat(/['\"]/);\n          }\n        }\n\n        if (singleline) {\n          if (parserConf.singleLineStringErrors) return ERRORCLASS;else state.tokenize = tokenOuter;\n        }\n\n        return OUTCLASS;\n      }\n\n      tokenString.isString = true;\n      return tokenString;\n    }\n\n    function tokenStringFactory(delimiter, tokenOuter) {\n      while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0) {\n        delimiter = delimiter.substr(1);\n      }\n\n      var singleline = delimiter.length == 1;\n      var OUTCLASS = \"string\";\n\n      function tokenString(stream, state) {\n        while (!stream.eol()) {\n          stream.eatWhile(/[^'\"\\\\]/);\n\n          if (stream.eat(\"\\\\\")) {\n            stream.next();\n            if (singleline && stream.eol()) return OUTCLASS;\n          } else if (stream.match(delimiter)) {\n            state.tokenize = tokenOuter;\n            return OUTCLASS;\n          } else {\n            stream.eat(/['\"]/);\n          }\n        }\n\n        if (singleline) {\n          if (parserConf.singleLineStringErrors) return ERRORCLASS;else state.tokenize = tokenOuter;\n        }\n\n        return OUTCLASS;\n      }\n\n      tokenString.isString = true;\n      return tokenString;\n    }\n\n    function pushPyScope(state) {\n      while (top(state).type != \"py\") {\n        state.scopes.pop();\n      }\n\n      state.scopes.push({\n        offset: top(state).offset + conf.indentUnit,\n        type: \"py\",\n        align: null\n      });\n    }\n\n    function pushBracketScope(stream, state, type) {\n      var align = stream.match(/^([\\s\\[\\{\\(]|#.*)*$/, false) ? null : stream.column() + 1;\n      state.scopes.push({\n        offset: state.indent + hangingIndent,\n        type: type,\n        align: align\n      });\n    }\n\n    function dedent(stream, state) {\n      var indented = stream.indentation();\n\n      while (state.scopes.length > 1 && top(state).offset > indented) {\n        if (top(state).type != \"py\") return true;\n        state.scopes.pop();\n      }\n\n      return top(state).offset != indented;\n    }\n\n    function tokenLexer(stream, state) {\n      if (stream.sol()) state.beginningOfLine = true;\n      var style = state.tokenize(stream, state);\n      var current = stream.current(); // Handle decorators\n\n      if (state.beginningOfLine && current == \"@\") return stream.match(identifiers, false) ? \"meta\" : py3 ? \"operator\" : ERRORCLASS;\n      if (/\\S/.test(current)) state.beginningOfLine = false;\n      if ((style == \"variable\" || style == \"builtin\") && state.lastToken == \"meta\") style = \"meta\"; // Handle scope changes.\n\n      if (current == \"pass\" || current == \"return\") state.dedent += 1;\n      if (current == \"lambda\") state.lambda = true;\n      if (current == \":\" && !state.lambda && top(state).type == \"py\") pushPyScope(state);\n\n      if (current.length == 1 && !/string|comment/.test(style)) {\n        var delimiter_index = \"[({\".indexOf(current);\n        if (delimiter_index != -1) pushBracketScope(stream, state, \"])}\".slice(delimiter_index, delimiter_index + 1));\n        delimiter_index = \"])}\".indexOf(current);\n\n        if (delimiter_index != -1) {\n          if (top(state).type == current) state.indent = state.scopes.pop().offset - hangingIndent;else return ERRORCLASS;\n        }\n      }\n\n      if (state.dedent > 0 && stream.eol() && top(state).type == \"py\") {\n        if (state.scopes.length > 1) state.scopes.pop();\n        state.dedent -= 1;\n      }\n\n      return style;\n    }\n\n    var external = {\n      startState: function startState(basecolumn) {\n        return {\n          tokenize: tokenBase,\n          scopes: [{\n            offset: basecolumn || 0,\n            type: \"py\",\n            align: null\n          }],\n          indent: basecolumn || 0,\n          lastToken: null,\n          lambda: false,\n          dedent: 0\n        };\n      },\n      token: function token(stream, state) {\n        var addErr = state.errorToken;\n        if (addErr) state.errorToken = false;\n        var style = tokenLexer(stream, state);\n        if (style && style != \"comment\") state.lastToken = style == \"keyword\" || style == \"punctuation\" ? stream.current() : style;\n        if (style == \"punctuation\") style = null;\n        if (stream.eol() && state.lambda) state.lambda = false;\n        return addErr ? style + \" \" + ERRORCLASS : style;\n      },\n      indent: function indent(state, textAfter) {\n        if (state.tokenize != tokenBase) return state.tokenize.isString ? CodeMirror.Pass : 0;\n        var scope = top(state),\n            closing = scope.type == textAfter.charAt(0);\n        if (scope.align != null) return scope.align - (closing ? 1 : 0);else return scope.offset - (closing ? hangingIndent : 0);\n      },\n      electricInput: /^\\s*[\\}\\]\\)]$/,\n      closeBrackets: {\n        triples: \"'\\\"\"\n      },\n      lineComment: \"#\",\n      fold: \"indent\"\n    };\n    return external;\n  });\n  CodeMirror.defineMIME(\"text/x-python\", \"python\");\n\n  var words = function words(str) {\n    return str.split(\" \");\n  };\n\n  CodeMirror.defineMIME(\"text/x-cython\", {\n    name: \"python\",\n    extra_keywords: words(\"by cdef cimport cpdef ctypedef enum except \" + \"extern gil include nogil property public \" + \"readonly struct union DEF IF ELIF ELSE\")\n  });\n});"],"sourceRoot":""}